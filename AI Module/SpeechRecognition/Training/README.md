
<p align="center">
  <a href="" rel="noopener">
 <img src="images/challenge.png" alt="Project logo"></a>
<!-- </p> -->

<h3 align="center">Speech Recognition</h3>
---

<p align="center"> Welcome to the IEEE ESPRIT SB Team's Human Exploration Rover Challenge (HERC) Speech Recognition Training repository. This project focuses on refining multilingual pre-trained speech models for Automatic Speech Recognition (ASR), with the ultimate goal of enabling spoken communication between astronauts and rovers.
    <br> 
</p>

## ğŸ“ Table of Contents

- [Overview](#overview)
- [Dataset](#dataset)
- [Installation](#installation)
- [Hugging Face Integration](#hugging-face-integration)
- [Data Preparation](#data-preparation)
- [Tokenization and Vocabulary Creation](#tokenization-and-vocabulary-creation)
- [Training the Speech Recognition Model](#training-the-speech-recognition-model)
- [Evaluation](#evaluation)
- [Saving the Model](#saving-the-model)
- [Contribution](#contribution)
- [License](#license)

## ğŸ“ Overview

This project is centered around refining multilingual pre-trained speech models for Automatic Speech Recognition (ASR). The ultimate goal is to facilitate spoken communication between astronauts and rovers participating in the Human Exploration Rover Challenge (HERC).

## ğŸ“Š Dataset

The notebook is specifically designed to work with the TIMIT dataset, a corpus of read speech tailored for acoustic-phonetic studies and ASR system development. The TIMIT dataset, with its clean transcriptions, is ideal for training speech recognition models.

## âš™ï¸ Installation

Before running the notebook, ensure you have the necessary packages installed. Use the following commands to set up the environment:

```bash
!pip install datasets==1.14
!pip install transformers==4.11.3
!pip install librosa
!pip install jiwer
!apt install git-lfs
```

## ğŸ¤— Hugging Face Integration

This project leverages Hugging Face's model hub for version control, allowing efficient tracking and sharing of model checkpoints.

```python
from huggingface_hub import notebook_login
notebook_login()
```

## ğŸ› ï¸ Data Preparation

The TIMIT dataset undergoes preprocessing to eliminate irrelevant features. The notebook demonstrates how to display random samples and clean transcriptions.

## ğŸ”¡ Tokenization and Vocabulary Creation

The notebook illustrates the creation of a custom vocabulary for the ASR model. Special characters are removed, and a mapping function is utilized to create a set of characters.

## ğŸš€ Training the Speech Recognition Model

Training is conducted using the Wav2Vec2 model. The notebook guides you through loading the model, defining a data collator, and configuring the training process.

## ğŸ“Š Evaluation

The primary evaluation metric is the Word Error Rate (WER). The notebook includes a function to compute WER, ensuring the model's performance is assessed during training.

## ğŸ’¾ Saving the Model

The trained model is saved in a format compatible with the DeepSpeech library. The conversion process from the Hugging Face model to DeepSpeech is detailed in the notebook.

## ğŸ¤ Contribution

Contributions are welcome! If you encounter issues or have suggestions for improvements, feel free to open an issue or submit a pull request.

## ğŸ“„ License

This project is licensed under the [MIT License](LICENSE).